<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="This is the Homepage of the ECCV2024 Workshop EVAL: Emergent Visual Abilities and Limits of Foundation Models">
  <meta name="keywords" content="Emergent Visual Abilities, Emergent Abilities, Benchmarks and Evaluations, Visual Shortcomings, Interpretability, Vision-Language Models, Multimodal Foundation Models, Large Language Models, Large Multi Modal Models, Visual Reasoning, Visual Question Answering, Visual Hallucinations, Prompting, Visual Imagination, Visual Grounding">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EVAL: Emergent Visual Abilities and Limits of Foundation Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Visual Emergent Abilities and Visual Limits of Foundation Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">How do we analyse and evaluate the visual capabilities that seem to emerge in foundation multimodal models?</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://eccv2024.ecva.net/"> ECCV 2024 Workshop, Milan, Italy</a></span> 
          </div>

          
          <div class="is-size-5 publication-authors">
            <span class="author-block">Date: TBA</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Location: TBA</span>
          </div>




          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a rel="noopener" target="_blank" href="#schedule"
                   class="external-link button is-normal is-rounded is-dark">
                  <!--<span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>-->
                  <span>Schedule</span>
                </a>
              </span>
              <span class="link-block">
                <a rel="noopener" target="_blank" href="#schedule"
                   class="external-link button is-normal is-rounded is-dark">
                  <!--<span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>-->
                  <span>Speakers</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a rel="noopener" target="_blank" href="#organizers"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Organizers</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a rel="noopener" target="_blank" href="#reviewers"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Reviewers</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <h1 class="title has-text-centered">
        <span class="overview"> Overview </span>
      </h1>
      <span class="pitch"> 
      The research and industry landscape is dramatically evolving due to the capabilities of large Foundation Models (FM) like Dino, CLIP, Stable Diffusion, LLaVa, Gemini, GPT4-V, DallE etc.
        As these models and their training sets scale in size, unexpected abilities seem to emerge even when they are not intentionally programmed or anticipated. 
        However, their key role in overtaking other models on standard benchmarks undescores for the necessity for new evaluations. The inadequacy of current benchmarks,
        combined with the undisclosed information about the training sets hampers the understanding and characterization of these capabilities. 
        Furthermore, recent studies have pointed out these models exhibit specific limitations and failures, stressing the need to identify methodologies to identify these shortcomings.
        In this workshop, we invite researchers to present works that aim at <emph>analysing and evaluating emergent visual abilities.</emph>
        This includes identifying new capabilities, pinpointing shortcomings, and understanding the factors that lead to their emergance.

        We exemplify some of the visual emergent abilities and limits to inspire, not limit, possible relevant contriutions to our workshop: 
        <ul>
          <li><b>Visual Reasoning</b>: Investigate how FMs explicitly or implicitly support spatial, temporal and causal reasoning about the visual world</li>
          <li><b>Interpretability</b>: Probe neurons and latent representations to identify if they form a semantic or mechanistic understanding of visual concepts </li>
          <li><b>Object, Part, Segment Discovery</b>: Identify the ability to inherently detect objects, their boundaries, and parts </li>
          <li><b>Prompting</b>: Study how prompting these models makes learned but unobserved capabilities emerge or overcome shortcomings </li>
          <li><b>Event-Centric Understanding</b>: Capabilities beyond object-centric understanding by leveraging relationships, context and external knowledge</li>
          <li><b>Visual Imagination</b>: e.g., do LLMs have spatial and visual understanding abilities to solve tasks?</li>
          <li><b>Invariant Understanding</b>: Do models form similar embeddings for different representations of the same concept? </li>
          <li><b>Semantic Metrics</b>: Are the embedding spaces and distance metrics defined over them capturing specific stylistic or semantic aspects of the input? </li>
          <li><b>Understanding 3D</b>: e.g., Do models trained on 2D data show 3D understanding?</li>
          <li><b>Hallucination</b>: How do we evaluate the hallucinated content of image generation models? How do we identify the hallucinations of VLMs in tasks such as image captioning and VQA?</li>
          <li><b>Visual Abstraction</b>: Are these models capable of visual abstraction similar to the ones of humans? Do they follow Gestalt perceptual principles?</li>
          <li><b>Robustness</b>: Analyzing the robustness to ouf-of-distribution inputs or adversarial inputs emergence in FMs</li>
          <li><b>Faithfulness</b>: Do the generated outputs (text or image) align with the input data, the desired behavior and the general knowledge?</li>
          <li><b>Bias</b>: Does an FM show poorer performance on part of the input domain?</li>
          <li><b>Visual Grounding</b>: e.g., Are generated outputs of multimodal LLMs grounded on the visual input, or is it a response purely based on language processing? </li>
          <li><b>Visual Chain-of-Thought</b>: Analyzing Chain-of-Thought reasoning for solving visual tasks in multimodal LLMs.</li>
          <li><b>Visual In-Context and Few-Shot Learning</b>: How and to what extent can FMs learn novel tasks in-context with limited examples?</li>
          <li><b>Miscellaneous Visual Capabilities (or Shortcomings)</b>: understanding quantities and count, OCR, fine-grained class recognition, pose estimation of objects or cameras etc.</li>

        </ul>
        

      
      
      </span>
    </div>
  </div>
</section>

<section 


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
